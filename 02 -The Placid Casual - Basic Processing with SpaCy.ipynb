{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at basic text pre-procwssing using spaCy\n",
    "\n",
    "Using the default spaCy model, examining outputs and developing our own pipleine.\n",
    "Before you start make sure you have installed spacy and the ```en``` model:\n",
    "\n",
    "```conda install -c conda-forge spacy```\n",
    "<br>\n",
    "```python -m spacy download en```\n",
    "<br>\n",
    "\n",
    "See the [spaCy](https://spacy.io) documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.tokens import Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Paw print marks leave a telltale sign\n",
    "There's a furry friend loose and committing a crime\n",
    "Takes no precaution leaving the fold\n",
    "For the placid casual have remote control\n",
    "Fuzz clogs up my video\n",
    "What do we do now?\n",
    "Now we are free again\n",
    "Freetown rocked in Sierra Leone\n",
    "When Valentine Strasser danced his way to the throne\n",
    "Gunpowder smoke took a heavy toll\n",
    "But they weren't placid casual so they lost control\n",
    "Fuzz clogs up my video\n",
    "What do we do now?\n",
    "Now we are free again\n",
    "Fuzz clogs up my video\n",
    "What do we do now?\n",
    "Now we are free again\n",
    "Fuzz clogs up my video\n",
    "What do we do now?\n",
    "Now we are free again\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing the spaCy english model and applying it to our text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate the outputs\n",
    "spaCy has performed a lot of processing on the text. This includes: \n",
    "\n",
    "* Tokenisation - Segmenting text into words, punctuations marks etc.\n",
    "* Part-of-Speech (POS) tagging - Assigning word types to tokens, like verb or noun.\n",
    "* Dependency Parsing - Assigning syntactic dependency labels, describing the relations between individual tokens, like subject or object.\n",
    "* Lemmatization - Assigning the base forms of words. For example, the lemma of \"was\" is \"be\", and the lemma of \"rats\" is \"rat\".\n",
    "* Sentence Boundary Detection (SBD) - Finding and segmenting individual sentences.\n",
    "* Named Entity Recognition (NER) - Labelling named \"real-world\" objects, like persons, companies or locations.\n",
    "* Similarity - Comparing words, text spans and documents and how similar they are to each other.\n",
    "* Text Classification - Assigning categories or labels to a whole document, or parts of a document.\n",
    "* Rule-based Matching - Finding sequences of tokens based on their texts and linguistic annotations, similar to regular expressions.\n",
    "\n",
    "Lets have a look at some of these and how we can use them.\n",
    "\n",
    "### Tokenisation\n",
    "spaCy has split the text into indiviudal tokens, preserving punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', 'Paw', 'print', 'marks', 'leave', 'a', 'telltale', 'sign', '\\n', 'There', \"'s\", 'a', 'furry', 'friend', 'loose', 'and', 'committing', 'a', 'crime', '\\n', 'Takes', 'no', 'precaution', 'leaving', 'the', 'fold', '\\n', 'For', 'the', 'placid', 'casual', 'have', 'remote', 'control', '\\n', 'Fuzz', 'clogs', 'up', 'my', 'video', '\\n', 'What', 'do', 'we', 'do', 'now', '?', '\\n', 'Now', 'we', 'are', 'free', 'again', '\\n', 'Freetown', 'rocked', 'in', 'Sierra', 'Leone', '\\n', 'When', 'Valentine', 'Strasser', 'danced', 'his', 'way', 'to', 'the', 'throne', '\\n', 'Gunpowder', 'smoke', 'took', 'a', 'heavy', 'toll', '\\n', 'But', 'they', 'were', \"n't\", 'placid', 'casual', 'so', 'they', 'lost', 'control', '\\n', 'Fuzz', 'clogs', 'up', 'my', 'video', '\\n', 'What', 'do', 'we', 'do', 'now', '?', '\\n', 'Now', 'we', 'are', 'free', 'again', '\\n', 'Fuzz', 'clogs', 'up', 'my', 'video', '\\n', 'What', 'do', 'we', 'do', 'now', '?', '\\n', 'Now', 'we', 'are', 'free', 'again', '\\n', 'Fuzz', 'clogs', 'up', 'my', 'video', '\\n', 'What', 'do', 'we', 'do', 'now', '?', '\\n', 'Now', 'we', 'are', 'free', 'again', '\\n']\n"
     ]
    }
   ],
   "source": [
    "print([token.text for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatisation\n",
    "spaCy has also perfomed lemmatisation on the text. You can view these by looking atthe ```lemma_``` property rather that the ```text``` property of a token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', 'paw', 'print', 'mark', 'leave', 'a', 'telltale', 'sign', '\\n', 'there', 'be', 'a', 'furry', 'friend', 'loose', 'and', 'commit', 'a', 'crime', '\\n', 'take', 'no', 'precaution', 'leave', 'the', 'fold', '\\n', 'for', 'the', 'placid', 'casual', 'have', 'remote', 'control', '\\n', 'fuzz', 'clog', 'up', '-PRON-', 'video', '\\n', 'what', 'do', '-PRON-', 'do', 'now', '?', '\\n', 'now', '-PRON-', 'be', 'free', 'again', '\\n', 'freetown', 'rock', 'in', 'sierra', 'leone', '\\n', 'when', 'valentine', 'strasser', 'dance', '-PRON-', 'way', 'to', 'the', 'throne', '\\n', 'gunpowder', 'smoke', 'take', 'a', 'heavy', 'toll', '\\n', 'but', '-PRON-', 'be', 'not', 'placid', 'casual', 'so', '-PRON-', 'lose', 'control', '\\n', 'fuzz', 'clog', 'up', '-PRON-', 'video', '\\n', 'what', 'do', '-PRON-', 'do', 'now', '?', '\\n', 'now', '-PRON-', 'be', 'free', 'again', '\\n', 'fuzz', 'clog', 'up', '-PRON-', 'video', '\\n', 'what', 'do', '-PRON-', 'do', 'now', '?', '\\n', 'now', '-PRON-', 'be', 'free', 'again', '\\n', 'fuzz', 'clog', 'up', '-PRON-', 'video', '\\n', 'what', 'do', '-PRON-', 'do', 'now', '?', '\\n', 'now', '-PRON-', 'be', 'free', 'again', '\\n']\n"
     ]
    }
   ],
   "source": [
    "print([token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging\n",
    "\n",
    "spaCy has also tagged each token classifying if it is a digit, punctuation, etc. You can access these:\n",
    "\n",
    "* is_alpha\tbool\tDoes the token consist of alphabetic characters? Equivalent to token.text.isalpha().\n",
    "* is_ascii\tbool\tDoes the token consist of ASCII characters? Equivalent to [any(ord(c) >= 128 for c in token.text)].\n",
    "* is_digit\tbool\tDoes the token consist of digits? Equivalent to token.text.isdigit().\n",
    "* is_lower\tbool\tIs the token in lowercase? Equivalent to token.text.islower().\n",
    "* is_upper\tbool\tIs the token in uppercase? Equivalent to token.text.isupper().\n",
    "* is_title\tbool\tIs the token in titlecase? Equivalent to token.text.istitle().\n",
    "* is_punct\tbool\tIs the token punctuation?\n",
    "* is_left_punct\tbool\tIs the token a left punctuation mark, e.g. (?\n",
    "* is_right_punct\tbool\tIs the token a right punctuation mark, e.g. ]?\n",
    "* is_space\tbool\tDoes the token consist of whitespace characters? Equivalent to token.text.isspace().\n",
    "* is_bracket\tbool\tIs the token a bracket?\n",
    "* is_quote\tbool\tIs the token a quotation mark?\n",
    "* is_currency\tbool\tIs the token a currency symbol?\n",
    "* like_url\tbool\tDoes the token resemble a URL?*\n",
    "* like_num\tbool\tDoes the token represent a number? e.g. \"10.9\", \"10\", \"ten\", etc.\n",
    "* like_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "print([token.is_punct for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of Speech Tagging\n",
    "spaCy is able make a prediction of which tag or label most likely applies in this context. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SPACE   \n",
      "\n",
      "Paw PROPN NNP compound Xxx\n",
      "print NOUN NN compound xxxx\n",
      "marks NOUN NNS nsubj xxxx\n",
      "leave VERB VBP ROOT xxxx\n",
      "a DET DT det x\n",
      "telltale ADJ JJ compound xxxx\n",
      "sign NOUN NN dobj xxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "There ADV EX expl Xxxxx\n",
      "'s VERB VBZ ROOT 'x\n",
      "a DET DT det x\n",
      "furry ADJ JJ amod xxxx\n",
      "friend NOUN NN attr xxxx\n",
      "loose ADJ JJ amod xxxx\n",
      "and CCONJ CC cc xxx\n",
      "committing VERB VBG conj xxxx\n",
      "a DET DT det x\n",
      "crime NOUN NN dobj xxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Takes VERB VBZ conj Xxxxx\n",
      "no DET DT det xx\n",
      "precaution NOUN NN dobj xxxx\n",
      "leaving VERB VBG xcomp xxxx\n",
      "the DET DT det xxx\n",
      "fold NOUN NN dobj xxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "For ADP IN prep Xxx\n",
      "the DET DT det xxx\n",
      "placid ADJ JJ amod xxxx\n",
      "casual NOUN NN nsubj xxxx\n",
      "have VERB VBP conj xxxx\n",
      "remote ADJ JJ amod xxxx\n",
      "control NOUN NN dobj xxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Fuzz PROPN NNP compound Xxxx\n",
      "clogs VERB VBZ ROOT xxxx\n",
      "up PART RP prt xx\n",
      "my ADJ PRP$ poss xx\n",
      "video NOUN NN dobj xxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "What NOUN WP dobj Xxxx\n",
      "do VERB VBP aux xx\n",
      "we PRON PRP nsubj xx\n",
      "do VERB VB ROOT xx\n",
      "now ADV RB advmod xxx\n",
      "? PUNCT . punct ?\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Now ADV RB advmod Xxx\n",
      "we PRON PRP nsubj xx\n",
      "are VERB VBP ROOT xxx\n",
      "free ADJ JJ acomp xxxx\n",
      "again ADV RB advmod xxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Freetown PROPN NNP nsubj Xxxxx\n",
      "rocked VERB VBN ROOT xxxx\n",
      "in ADP IN prep xx\n",
      "Sierra PROPN NNP compound Xxxxx\n",
      "Leone PROPN NNP pobj Xxxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "When ADV WRB advmod Xxxx\n",
      "Valentine PROPN NNP compound Xxxxx\n",
      "Strasser PROPN NNP nsubj Xxxxx\n",
      "danced VERB VBD advcl xxxx\n",
      "his ADJ PRP$ poss xxx\n",
      "way NOUN NN dobj xxx\n",
      "to ADP IN prep xx\n",
      "the DET DT det xxx\n",
      "throne NOUN NN pobj xxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Gunpowder PROPN NNP compound Xxxxx\n",
      "smoke NOUN NN nsubj xxxx\n",
      "took VERB VBD ccomp xxxx\n",
      "a DET DT det x\n",
      "heavy ADJ JJ amod xxxx\n",
      "toll NOUN NN dobj xxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "But CCONJ CC cc Xxx\n",
      "they PRON PRP nsubjpass xxxx\n",
      "were VERB VBD auxpass xxxx\n",
      "n't ADV RB neg x'x\n",
      "placid ADJ JJ ROOT xxxx\n",
      "casual ADJ JJ acomp xxxx\n",
      "so ADP IN mark xx\n",
      "they PRON PRP nsubj xxxx\n",
      "lost VERB VBD advcl xxxx\n",
      "control NOUN NN dobj xxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Fuzz PROPN NNP nsubj Xxxx\n",
      "clogs VERB VBZ ROOT xxxx\n",
      "up PART RP prt xx\n",
      "my ADJ PRP$ poss xx\n",
      "video NOUN NN dobj xxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "What NOUN WP dobj Xxxx\n",
      "do VERB VBP aux xx\n",
      "we PRON PRP nsubj xx\n",
      "do VERB VB ROOT xx\n",
      "now ADV RB advmod xxx\n",
      "? PUNCT . punct ?\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Now ADV RB advmod Xxx\n",
      "we PRON PRP nsubj xx\n",
      "are VERB VBP ROOT xxx\n",
      "free ADJ JJ acomp xxxx\n",
      "again ADV RB advmod xxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Fuzz PROPN NNP compound Xxxx\n",
      "clogs VERB VBZ nsubj xxxx\n",
      "up PART RP prep xx\n",
      "my ADJ PRP$ poss xx\n",
      "video NOUN NN pobj xxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "What NOUN WP dobj Xxxx\n",
      "do VERB VBP aux xx\n",
      "we PRON PRP nsubj xx\n",
      "do VERB VB ROOT xx\n",
      "now ADV RB advmod xxx\n",
      "? PUNCT . punct ?\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Now ADV RB advmod Xxx\n",
      "we PRON PRP nsubj xx\n",
      "are VERB VBP ROOT xxx\n",
      "free ADJ JJ acomp xxxx\n",
      "again ADV RB advmod xxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Fuzz PROPN NNP compound Xxxx\n",
      "clogs VERB VBZ nsubj xxxx\n",
      "up PART RP prep xx\n",
      "my ADJ PRP$ poss xx\n",
      "video NOUN NN pobj xxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "What NOUN WP dobj Xxxx\n",
      "do VERB VBP aux xx\n",
      "we PRON PRP nsubj xx\n",
      "do VERB VB ROOT xx\n",
      "now ADV RB advmod xxx\n",
      "? PUNCT . punct ?\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Now ADV RB advmod Xxx\n",
      "we PRON PRP nsubj xx\n",
      "are VERB VBP ROOT xxx\n",
      "free ADJ JJ acomp xxxx\n",
      "again ADV RB advmod xxxx\n",
      "\n",
      " SPACE   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.tag_, token.dep_,token.shape_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing\n",
    "SpaCy has also performed some named entity recognition and parsing.\n",
    "\n",
    "### Named Entity Recognition (NER)\n",
    "Lets look at what spaCy has labelled as named entities - not ethat spaces and newlines seem to have been included here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text Fuzz -> labelled as PERSON is a space? False\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text Sierra Leone\n",
      " -> labelled as ORG is a space? False\n",
      "Text Valentine Strasser -> labelled as PERSON is a space? False\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text Fuzz -> labelled as PERSON is a space? False\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text Fuzz -> labelled as PERSON is a space? False\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text Fuzz -> labelled as PERSON is a space? False\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(\"Text {} -> labelled as {} is a space? {}\".format(ent.text,ent.label_, ent.text==\"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying the SpaCy model, we can now start to process the test is an appropriate manner for our needs. Fpor example, for sentiment analysis we may need to look at sentance structure and meaning, and so we will need the parsing information and punctuation. For statistical models we will want to remove any potential noise like punctuation and stopwords. For example, to remove stop words we could:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Paw print marks leave telltale sign \n",
      " There 's furry friend loose committing crime \n",
      " Takes precaution leaving fold \n",
      " For placid casual remote control \n",
      " Fuzz clogs video \n",
      " What ? \n",
      " Now free \n",
      " Freetown rocked Sierra Leone \n",
      " When Valentine Strasser danced way throne \n",
      " Gunpowder smoke took heavy toll \n",
      " But n't placid casual lost control \n",
      " Fuzz clogs video \n",
      " What ? \n",
      " Now free \n",
      " Fuzz clogs video \n",
      " What ? \n",
      " Now free \n",
      " Fuzz clogs video \n",
      " What ? \n",
      " Now free \n",
      " \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Note that this function returns a Doc only and strips away any ner - so do this before applying ner!\n",
    "\n",
    "\"\"\"\n",
    "def remove_stopwords(doc):\n",
    "    token_pos = [None] \n",
    "    [token_pos.append(t.i) for t in doc if t.is_stop != False]        \n",
    "    doc = Doc(doc.vocab, words=[t.text for i, t in enumerate(doc) if i not in token_pos])\n",
    "    return doc\n",
    "\n",
    "print(remove_stopwords(doc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Paw print marks leave telltale sign \n",
      " There 's furry friend loose committing crime \n",
      " Takes precaution leaving fold \n",
      " For placid casual remote control \n",
      " Fuzz clogs video \n",
      " What ? \n",
      " Now free \n",
      " Freetown rocked Sierra Leone \n",
      " When Valentine Strasser danced way throne \n",
      " Gunpowder smoke took heavy toll \n",
      " But n't placid casual lost control \n",
      " Fuzz clogs video \n",
      " What ? \n",
      " Now free \n",
      " Fuzz clogs video \n",
      " What ? \n",
      " Now free \n",
      " Fuzz clogs video \n",
      " What ? \n",
      " Now free \n",
      " \n",
      "()\n"
     ]
    }
   ],
   "source": [
    "def remove_stopwords(doc):\n",
    "    token_pos = [None] \n",
    "    [token_pos.append(t.i) for t in doc if t.is_stop != False]        \n",
    "    doc2 = Doc(doc.vocab, words=[t.text for i, t in enumerate(doc) if i not in token_pos])\n",
    "    #doc2.ents = [e for i, e in enumerate(doc.ents) if i not in token_pos]\n",
    "    return doc2\n",
    "\n",
    "d = remove_stopwords(doc)\n",
    "print(d)\n",
    "\n",
    "#NOte that there are no ents on this - just a pure doc. So run NER after this to get NER values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get over the issue that spaCy is classifying whitespaces and newlines as named entities:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Fuzz -> labelled as PERSON\n",
      "Text Sierra Leone\n",
      " -> labelled as ORG\n",
      "Text Valentine Strasser -> labelled as PERSON\n",
      "Text Fuzz -> labelled as PERSON\n",
      "Text Fuzz -> labelled as PERSON\n",
      "Text Fuzz -> labelled as PERSON\n"
     ]
    }
   ],
   "source": [
    "def remove_whitespace_entities(doc):\n",
    "    doc.ents = [ent for ent in doc.ents if (ent.text != ' ') and (ent.text != '\\n')  ]\n",
    "    return doc\n",
    "\n",
    "\n",
    "doc = remove_whitespace_entities(doc)\n",
    "for ent in doc.ents:\n",
    "    print(\"Text {} -> labelled as {}\".format(ent.text,ent.label_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising the parsing\n",
    "It is possible to visualise the parsing on using ```displaCy```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"1100\" height=\"312.0\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Now</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">we</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">are</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">free</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">again</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">\n",
       "</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\"></tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\"></textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M920.0,179.0 L928.0,167.0 912.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "sentence_spans = list(doc.sents)\n",
    "displacy.render(sentence_spans[4], style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">Freetown rocked in Sierra Leone</br>When Valentine Strasser danced his way to the throne</br>Gunpowder smoke took a heavy toll</br>\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    \n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    \n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    \n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    \n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(sentence_spans[5], style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "When we apply the SpaCy model using ```nlp(text)``` spaCy is actually applying several processing steps in series. Each process is applied in turn and the oputput sent to the next process. This is termed a processing pipleine. \n",
    "\n",
    "Instead of applying functions after applying the spaCy model, we can also add them to the default spaCy pipeline. In that was we can develop our own custom spaCy pipelines for our needs. This is a really cool and tidy way of processing our text.\n",
    "\n",
    "Lets explore this - lets start by loading the default model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_custom = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The default pipeline\n",
    "We can view the default pipeline is by calling ```pipeline```. We can see that by default SpaCy applies a tagger, a dependency parser and then a entity recoignizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.Tagger at 0x107195940>),\n",
       " ('parser', <spacy.pipeline.DependencyParser at 0x10873c048>),\n",
       " ('ner', <spacy.pipeline.EntityRecognizer at 0x104607af0>)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_custom.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remove any process that we dont want. This can speed up performance espcially on very large bodies of text. For example, if we only intend to do statistical analysis and do not need dependency parsing we can remove it from the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customising the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can remove any process that we dont want that can be time consuming but arent required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.Tagger at 0x107195940>),\n",
       " ('ner', <spacy.pipeline.EntityRecognizer at 0x104607af0>)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_custom.remove_pipe('parser')\n",
    "nlp_custom.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add our own functions to the pipeline.\n",
    "NB - run remove stopwords BEFORE ner - so we perfrom the NER on the reduced body of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.Tagger at 0x107195940>),\n",
       " ('rem_stpw', <function __main__.remove_stopwords(doc)>),\n",
       " ('ner', <spacy.pipeline.EntityRecognizer at 0x104607af0>),\n",
       " ('rem_ws_ent', <function __main__.remove_whitespace_entities(doc)>)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_custom.add_pipe(remove_stopwords, name='rem_stpw', after = 'tagger')\n",
    "nlp_custom.add_pipe(remove_whitespace_entities, name='rem_ws_ent', after = 'ner')\n",
    "\n",
    "nlp_custom.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the spaCy model now also removes stopwords and whistespaces from the entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Paw print marks leave a telltale sign\n",
      "There's a furry friend loose and committing a crime\n",
      "Takes no precaution leaving the fold\n",
      "For the placid casual have remote control\n",
      "Fuzz clogs up my video\n",
      "What do we do now?\n",
      "Now we are free again\n",
      "Freetown rocked in Sierra Leone\n",
      "When Valentine Strasser danced his way to the throne\n",
      "Gunpowder smoke took a heavy toll\n",
      "But they weren't placid casual so they lost control\n",
      "Fuzz clogs up my video\n",
      "What do we do now?\n",
      "Now we are free again\n",
      "Fuzz clogs up my video\n",
      "What do we do now?\n",
      "Now we are free again\n",
      "Fuzz clogs up my video\n",
      "What do we do now?\n",
      "Now we are free again\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Paw print marks leave telltale sign \n",
      " There 's furry friend loose committing crime \n",
      " Takes precaution leaving fold \n",
      " For placid casual remote control \n",
      " Fuzz clogs video \n",
      " What ? \n",
      " Now free \n",
      " Freetown rocked Sierra Leone \n",
      " When Valentine Strasser danced way throne \n",
      " Gunpowder smoke took heavy toll \n",
      " But n't placid casual lost control \n",
      " Fuzz clogs video \n",
      " What ? \n",
      " Now free \n",
      " Fuzz clogs video \n",
      " What ? \n",
      " Now free \n",
      " Fuzz clogs video \n",
      " What ? \n",
      " Now free \n",
      " \n"
     ]
    }
   ],
   "source": [
    "doc_pp = nlp_custom(text)\n",
    "print(doc_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Fuzz, Sierra Leone \n",
      ", Valentine Strasser, Fuzz, Fuzz, Fuzz)\n"
     ]
    }
   ],
   "source": [
    "print(doc_pp.ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This can be saved and used in the future for common text preprocessing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
